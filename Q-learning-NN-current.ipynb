{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and stuff\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate as integrate\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import IPython\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Constants for discretizing states. There are 50 states of theta and thetadot each.\n",
    "State 0 corresponds to theta = -pi, thetadot = -6.5m/s\n",
    "State 2499 corresponds to theta = pi, thetadot = 6.5m/s\n",
    "States [24, 25, 2474 and 2475] have values that approximately equal theta = -pi , thetadot = 0 \n",
    "These 4 states are considered goal states.\n",
    "'''\n",
    "maxVelocity = 6.5\n",
    "thetaStates = 50\n",
    "thetaDotStates = 50\n",
    "thetaStepSize = 2*math.pi/49\n",
    "thetaDotStepSize = 2*maxVelocity/49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pendulum(state,action):\n",
    "    \n",
    "    '''\n",
    "    This function takes state(number from 0 to 2499 ) and action (0, 1 or 2) and computes the next state\n",
    "    of the pendulum based on the action. \n",
    "    \n",
    "    '''\n",
    "    #constants\n",
    "    GRAVITY = 9.8\n",
    "    LENGTH = 1.0\n",
    "    dt1 = 0.001\n",
    "    FORCE = 4.0\n",
    "    time = 200\n",
    "    if (action == 0):\n",
    "        u = -FORCE\n",
    "    elif(action == 1):\n",
    "        u = FORCE\n",
    "    elif(action == 2):\n",
    "        u = 0\n",
    "    # Get values of theta and thetadot that correspond to the state\n",
    "    theta, thetaDot = get_values(state)\n",
    "    \n",
    "    # Do Euler update of values for theta and thetadot to calculate the new theta and thetadot \n",
    "    for i in range(time):\n",
    "        \n",
    "        newThetaDot = thetaDot + dt1*(-(GRAVITY/LENGTH)*np.sin(theta) + u)\n",
    "        newTheta = theta + dt1*newThetaDot\n",
    "        \n",
    "        theta = ((newTheta + np.pi)%(2*np.pi)) - np.pi\n",
    "        thetaDot = np.clip(newThetaDot, -maxVelocity, maxVelocity)\n",
    "    \n",
    "    #Discretize the values theta and thetadot back into a state(number from 0 to 2499)\n",
    "    next_state = get_state(newTheta, newThetaDot)\n",
    "    return next_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def get_state(theta, thetaDot):\n",
    "    '''\n",
    "    Discretize the values theta and thetadot back into a state(number from 0 to 2499)\n",
    "    '''\n",
    "    state = 0\n",
    "    for i in range (thetaStates):\n",
    "        for j in range (thetaDotStates):\n",
    "            if ((theta >= (-np.pi + thetaStepSize*i)) & (thetaDot >=(-maxVelocity + thetaDotStepSize*j))):\n",
    "                state = i*thetaStates + j    \n",
    "    return state\n",
    "\n",
    "def get_values(state):\n",
    "    '''\n",
    "    Get values of theta and thetadot that correspond to the state\n",
    "    '''\n",
    "    thetaDot = -maxVelocity + (state%thetaDotStates)*thetaDotStepSize\n",
    "    theta = -np.pi + int(state/thetaStates)*thetaStepSize\n",
    "    return theta, thetaDot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def draw_pendulum(theta_array):\n",
    "    '''\n",
    "    This function takes an array of theta values for each time instant and creates an animation. \n",
    "    \n",
    "    '''\n",
    "    x1 = np.sin(theta_array)\n",
    "    y1 = -np.cos(theta_array)\n",
    "\n",
    "    x1= x1[:,0::200]\n",
    "    y1= y1[:,0::200]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, autoscale_on=False, xlim=(-2, 2), ylim=(-2, 2))\n",
    "    ax.grid()\n",
    "\n",
    "    line, = ax.plot([], [], 'o-', lw=2)\n",
    "    time_template = 'time = %.1fs'\n",
    "    time_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n",
    "\n",
    "    dt = 0.0005\n",
    "    t = np.arange(0.0, 20, dt)\n",
    "\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        time_text.set_text('')\n",
    "        return line, time_text\n",
    "\n",
    "\n",
    "    def animate(i):\n",
    "        thisx = [0, x1[i]]\n",
    "        thisy = [0, y1[i]]\n",
    "\n",
    "        line.set_data(thisx, thisy)\n",
    "        time_text.set_text(time_template % (i*dt))\n",
    "        return line, time_text\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, np.arange(1, len(theta_array)),\n",
    "                                  interval=200, blit=True, init_func=init)\n",
    "\n",
    "\n",
    "    plt.close(fig)\n",
    "    plt.close(ani._fig)\n",
    "    IPython.display.display_html(IPython.core.display.HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# state transition table\n",
    "def generate_next_state():\n",
    "    \n",
    "    '''\n",
    "    This function makes a table of all possible states(rows) and \n",
    "    actions(columns) and records next state according to the pendulum dynamics.  \n",
    "    '''\n",
    "    next_states = np.zeros((thetaStates*thetaDotStates,3))\n",
    "    for i in range (thetaStates*thetaDotStates):\n",
    "        for j in range(3):\n",
    "            next_states[i,j] = int(pendulum(i,j))\n",
    "    #     print(next_states[i])\n",
    "    return next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# A matrix with next states, next_state = next_states[state,action]. This table can be used\n",
    "# to compute the next state of pendulum, given an action, at each step.\n",
    "next_states = generate_next_state()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "###  Defining Neural Network to store Q(s,a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H1, H2, D_out = 1, 2, 32, 32, 1\n",
    "\n",
    "# Create empty Tensor to hold input\n",
    "x = torch.empty(1, 2)\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "policy_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H1),\n",
    "    torch.nn.Linear(H1, H2),\n",
    "    torch.nn.Linear(H2, D_out),)\n",
    "\n",
    "#target_net is used to freeze the target every few steps\n",
    "target_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H1),\n",
    "    torch.nn.Linear(H1, H2),\n",
    "    torch.nn.Linear(H2, D_out),)\n",
    "\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def run_episode():\n",
    "    #hyperparameters and initial conditions for each episode\n",
    "    currentState = 1225\n",
    "    currentAct = 1.0\n",
    "    episodeSteps = 500\n",
    "    EPSILON = 0.25\n",
    "    GAMMA = 0.999\n",
    "    TARGET_UPDATE = 10\n",
    "    Qa_values = np.zeros(3)\n",
    "    Qa1_values = np.zeros(3)\n",
    "    \n",
    "    for i in range(episodeSteps):\n",
    "        #get next state based on current state and current best action \n",
    "        nextState = next_states[int(currentState),int(currentAct)]\n",
    "        \n",
    "        # set the reward for current state\n",
    "        if((currentState ==24)|(currentState ==25)|(currentState ==2474)|(currentState ==2475)):\n",
    "            reward = 0\n",
    "        else:\n",
    "            reward = -1\n",
    "        \n",
    "        #######\n",
    "        #evaluate Q(s,a) at current state and current best action from neural net\n",
    "        x[0][0] = currentState\n",
    "        x[0][1] = float(currentAct)\n",
    "        state_action_values = policy_net(x)\n",
    "        state_action_values.requires_grad_(True)\n",
    "        #######\n",
    "        \n",
    "        #######\n",
    "        #evaluate max_a(Q(s',a)) at current state and current best action from 'target' neural net \n",
    "        x[0][0] = nextState\n",
    "        x[0][1] = 0\n",
    "        Qa1_values[0] = target_net(x).detach()\n",
    "        x[0][1] = 1\n",
    "        Qa1_values[1] = target_net(x).detach()\n",
    "        x[0][1] = 2\n",
    "        Qa1_values[2] = target_net(x).detach()\n",
    "        nextAct1 = np.argmax(Qa1_values)\n",
    "        x[0][1] = float(nextAct1)\n",
    "        next_state_values = target_net(x).detach()\n",
    "        #######\n",
    "        \n",
    "        # Target value for our loss function\n",
    "        expected_state_action_values = (next_state_values * GAMMA) + reward\n",
    "        expected_state_action_values.requires_grad_(True)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(state_action_values, expected_state_action_values)\n",
    "        loss = Variable(loss, requires_grad = True)\n",
    "        \n",
    "        # Update policy\n",
    "        policy_net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        ########\n",
    "        # Best next action for next state, evaluated from our model, policy_net. \n",
    "        if (EPSILON > random.randint(1,10)*0.1):\n",
    "            nextAct = np.array(random.randint(0,2))\n",
    "        else:\n",
    "            x[0][0] = nextState\n",
    "            \n",
    "            x[0][1] = 0\n",
    "            Qa_values[0] = policy_net(x).detach()\n",
    "\n",
    "\n",
    "            x[0][1] = 1\n",
    "            Qa_values[1] = policy_net(x).detach()\n",
    "\n",
    "\n",
    "            x[0][1] = 2\n",
    "            Qa_values[2] = policy_net(x).detach()\n",
    "\n",
    "            nextAct = np.argmax(Qa_values)\n",
    "        ########\n",
    "        \n",
    "        \n",
    "        #update state\n",
    "        currentState = nextState\n",
    "        currentAct = nextAct\n",
    "        # Update the target network, copying all weights and biases in policy_net\n",
    "        if i % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run episodes  \n",
    "for i in range(1000):\n",
    "    run_episode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val act 0 [-230.96757507]\n",
      "val act 1 [-230.91448975]\n",
      "val act 2 [-230.86140442]\n",
      "2\n",
      "val act 0 [-230.96757507]\n",
      "val act 1 [-230.91448975]\n",
      "val act 2 [-230.86140442]\n",
      "2\n",
      "val act 0 [-230.96757507]\n",
      "val act 1 [-230.91448975]\n",
      "val act 2 [-230.86140442]\n",
      "2\n",
      "val act 0 [-230.96757507]\n",
      "val act 1 [-230.91448975]\n",
      "val act 2 [-230.86140442]\n",
      "2\n",
      "val act 0 [-230.96757507]\n",
      "val act 1 [-230.91448975]\n",
      "val act 2 [-230.86140442]\n",
      "2\n",
      "val act 0 [-230.96757507]\n",
      "val act 1 [-230.91448975]\n",
      "val act 2 [-230.86140442]\n",
      "2\n",
      "val act 0 [-230.96757507]\n",
      "val act 1 [-230.91448975]\n",
      "val act 2 [-230.86140442]\n",
      "2\n",
      "val act 0 [-230.96757507]\n",
      "val act 1 [-230.91448975]\n",
      "val act 2 [-230.86140442]\n",
      "2\n",
      "val act 0 [-230.96757507]\n",
      "val act 1 [-230.91448975]\n",
      "val act 2 [-230.86140442]\n",
      "2\n",
      "val act 0 [-230.96757507]\n",
      "val act 1 [-230.91448975]\n",
      "val act 2 [-230.86140442]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Here I'm trying to get a sequence of actions from the model that has already learned.\n",
    "# Start at the pendulum down position at state = 1225\n",
    "St = 1225\n",
    "NextValue = np.zeros((3,1))\n",
    "policy = np.zeros((500,1))\n",
    "\n",
    "# Get 10 steps from the trained model\n",
    "# Get the best next step for each state by comparing all three state-action values.\n",
    "# Store each step in policy \n",
    "for i in range(10):\n",
    "    policy[i] = St\n",
    "\n",
    "    x[0][0] = St\n",
    "    x[0][1] = 0\n",
    "    NextValue[0] = target_net(x).detach()\n",
    "    print('val act 0',NextValue[0])\n",
    "    \n",
    "    x[0][1] = 1\n",
    "    NextValue[1] = target_net(x).detach()\n",
    "    print('val act 1',NextValue[1])\n",
    "    \n",
    "    x[0][1] = 2\n",
    "    NextValue[2] = target_net(x).detach()\n",
    "    print('val act 2',NextValue[2])\n",
    "    \n",
    "    nextAct = int(np.argmax(NextValue))\n",
    "    print(nextAct)\n",
    "    newState = next_states[St,nextAct]\n",
    "    St = int(newState)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"432\" height=\"288\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAg1m1kYXQAAAKtBgX//6ncRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9OSBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49NSBzY2VuZWN1dD00MCBpbnRyYV9yZWZyZXNo\n",
       "PTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0wLjYwIHFw\n",
       "bWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAAFMhliIQA\n",
       "FP/+98dPwKbo+WbLnUU9ITCK2PpIKL1Y7NAydQAAAwAARMD9n/7PvX4gJ4mVoMNs+cmuVU5lHW1w\n",
       "tpoNC79s7jKsKRaLWCfGNMEFH3yXNmUDw9qEyYkFk8xiMF/I3+qDUYrgnkQABnaG8G15Dhwy4ryI\n",
       "lPbpCTsVrOWZTOGVrNv10ijPOire960r9znhlOUc/NRIWochbxHKSEOx9WKpF3zmJr9jaeGKj3+J\n",
       "0/fYDp/J2Dl+GPnvu8Zx9PtSqKeDxSRG6KHrEkdnWRGifzcV/8E5gvfdKb2059D9KKLNPVLaOGX3\n",
       "EslwRHEXpgVYf71DBBgf8MFyBppl6G2P4HmO64G+1WAhgwkSLTbz/iGd/WuKP9VoS1ReMZYjSZv9\n",
       "FD0Z0vz+erjm6qQCzjK7fHddFqBYKr1j/eoXV4RrtY0V+pqd6NprGMNlVhUUgEHCYTX/XvIjRYfy\n",
       "qxSEfdCu4Dj+614lq90I0Ivi++/GxujaFnbe8nBQhIVLmgPdfCd8xrKYnD/DLijBkiJJQFkR9GvN\n",
       "kIt1RLCAfMHE78UR0iTGM3OjLp6xegdj1JjmgkNjbm43DoE100KT3qBHSaQUD1riGz7djgAW0RMS\n",
       "xF6FdpMLSUOiuWSGZzD6wH3azArlzHCrl8eKdz4BbL/22ImZFyq31IDM71KjfOqhZG+Aq3eZUtVQ\n",
       "WUANZyJ934P4AJ6ed9C0mpu6RQ4DuBs8BUP8+x4T0ZCpHA+pIULbbjCB1kYbImtKDf5mFQ1BUrrv\n",
       "ZGbryqSCgS3Ou8u1Hx1lIWPUdPFWQiQGuwfHvEaATkMqnmTmZ1v2WaR9G4oq3kNVpiCRnq4Wv7DV\n",
       "urHA56RcpuNg4k+mRkKbfdDJiNBwvS9MOUJx+B3dFeiQWsS7BVNQe5v7lP9MB9UcMnwRuQ9x91dj\n",
       "8BrrkCGUiRonstVU6Xb9ixqlRfanhdXq2pnA9ArGnwi2XPDeCTfFp+oWGJj9ycrY+LoBPRyuUrmW\n",
       "6dicmuQ36XW21NmF8QkOZwVpFWGBJuIteSnejJz2IT2M8BT94xZd67YE7eNgvnWEomiDiwcPMx2F\n",
       "e+8CEhE+0ZIe7rxH/iZ+aL/FPPTc7YXP+i6SGOxOWapXDliuYGk7aKeTAb0KBxqnRwzNEU5qHPSd\n",
       "70OxwTikwFlcKBB6UEmxbFbP///KFcGHzhXQyZCrKpkoLqE1pzfWo96PCEzFjOkRXx8UWDb//82L\n",
       "osY3e5Xzh9OLNaa2JlifGm9O/p/CvAmVU0dhU8FxpGvnyQ+XEkQ3FPovRfbfkbfBthjxFerFufQ9\n",
       "pzrG+XgMA9OGAE28pAfrn+56FKuRO4/Fa76Zn11F07uJls1sRyC9B/YOioz5tvmb+iH9Trwnd8z5\n",
       "AaaU518RnE7b2qmQCwnGpPy2BxDfazqTeeO3HAhdo4zdtWDQN2aPGEKpAcKZoJ567ENzg2vVhdaD\n",
       "m4nLD6wGvF7DlLQTdAN2xJToboIx0ApMynGVmItB5AkEB6d2L1cFtUCyjEgN6ko1gM1NP8vPZcp0\n",
       "3SZfwaQhJrY5SK59FARcHLBEr2xyARLoNz7T/YJxhPWjj1hMGbRCWoNH9wE2Rq/21o3zpH2Kdshv\n",
       "f17v4dngA36KqA95qTrhHUZqO26M0t6nuLO6B5LykO5yZsf8AdS9fVSmdGHPr/KVH2cvO4izrs+6\n",
       "VnsVFZ3v/yJ5//6iOoyJMDO+XlnqacjYTbawjHO7rPNJXrQs2e46ULpyQl/h5bO//f3d2h5sFNWF\n",
       "JN3+Tk1l7KEg6LzkyTgAACiy++Lnj3bNvDqTgafQwPLVyn2NJG2l5wYDDQU/jaMsemlyASD11Lph\n",
       "+E6mSI2dOIQM/3wbrgtqge+cvpNZb9eRslMOdTHiP7d5LiPoIMv2kokkXAxkxz6cFEr+KtNCN58t\n",
       "tZUawP+BAyt0Qt3XmYnA5ieumdfx6xnp/Ioe03XNLwpoY7Pp+7LdckvwztDuOpe2BDbMGu6Es4P0\n",
       "L5VXFWcdBn5Lxyz1M+Gy/v7LJpfoaJ/RLjPupZAElywK92sLps1eigi2nc/UD2/jErCyCSuT10h4\n",
       "XpuSg6o3S4Ehc7Xnf/u+s+t7oZUZ6IARmLBNDebHyjPSmJg4jsQDHCWdGvDPgabToQj5/7YSdrT3\n",
       "Hw1RS7ccwaS4m/wTVkHF4sPtVpyfidYFUDwHwvloh4As9MGpEgHu//tsmVNbgxdmu3LFRQYnH9oW\n",
       "TPnVoIc34dq3og/flPplM/txgeppwL9tsgGECOEfIwsZARZDkJuPzg7doLIvhtRAJ6yC81TeryH/\n",
       "fRfn/J2cmiE3RHR+Nqq+623BpDLtIOfhhMnjmO9BtvHvmkrZZNW0WIsISIier699NwXA6/391UO3\n",
       "NqaFB1fjXx8zj7Zip7//cB/sp7AAnVvGyH4Nm7/41EWmlDC4gKpqaE5JnFw9xEG5uK0Ej7PYHx+e\n",
       "6oLfP+dVhhtp3AM0DIbEuhzpExbBpZXQwccIjm/tPRruBjI/ct+jO3lIAfeLItjHGL7uThtUJXIm\n",
       "r//1RGjp+RsYyA+Wr4aGB9sgPTKZTH+ijR8AWj1f6WuKsk1IVv/aVHv6nZOp9oHL8icOQVuolunc\n",
       "FKVSMqMHmnK3rVLgpDmdn2sV/qr6ydj9jZyj1qO1JicFAR07e7OlvMtRPpM8yjB/0eRmUE/ga9xt\n",
       "jsBGyjP+bhDwAKPgqhyax3pWai+AqqX+JC2kg5N81oA5sF0GCcHl/RbhCQX+CXfJ9ybhnJiOCTR8\n",
       "dhlOwmc+oN4YXW8G9mgnGJ5403hFVecs2/+//TfDuMP7aAxPSDq4H35OZkB8VHbDA3mgEqR2u1GJ\n",
       "SZjPiqNGVB3MOfjqMe5t1oompAWV2Tujxz+3S+UW/ogjSuIInpwtGEuKxlbcUZG1JSWCFuXwOa5J\n",
       "T9Iu2d4JUi8tJwdlTV9Qk45aMRylS4c9ytTJUsZbxyCUpp6SRp7Sv6Jar+bxXAIbtEzwJrlYE9UP\n",
       "GWRI7g6wupC3QvlkOega3Ji4llV+dLOoz1J23IJPy6P3Utaf7mdB5eVqmNFI+PXzpo04hM2ieLNg\n",
       "vaT2z7Osyvr7R3ngdKnOrEEFBnSffr2Q4U7HX3wD5CEs2nwArfZTwppCkI7XPlnDcS1Mjjhg1QwK\n",
       "+DLF9AN2sp2Jo9rEJ8ZzNeELMi6eERRUiH0ukglLqf3xz9EgET8tzJA/pB+KTDcmJotN/z1uHcY4\n",
       "Zaz2IOYKLXR98ELgs4HAX5tbyG/xRMr6G67/GBS13ml5hvDF2yfl2RgQnINTLyHKUggvtBnRWo0u\n",
       "gHqiq6RV1KVFgaU1+0800Ya26ofzxbFMOmitHs7z2d52pRM7GavBtvv6gLIhbJyA+1N6Jjx7KHlK\n",
       "EpOuzlPAzq9C4jdPrUGhKbRU+rvs8IdU5HnDyVIr8YkQibprJFZvuvJ49MkyK2+kVKnjUEONID+f\n",
       "Spv1cK6XJvXr9k1VBnbLUP8EFuv/+ZB0ddZ7RZf4mt27iH/unlWiKmtIc2nRsZUFcIsS/xJ5+CXV\n",
       "/jO1cBb4G+jZ5LbmGEg+de+j70GlODbKF7kykRcB+me+o5uy+XvIswE4QxVHHjrknPTL0F3Wo+m4\n",
       "oCLcMz7LPqD0nDpWsI1FKf1+NFjgjXaN+IUCbriOcsBukfcQWuUKaVoGF4gLjFdex0N2fVq75Evm\n",
       "lhPLOAdSkzg9k47VkPpJg4PjEMn6Mu5cXjcZXI03tseMdokXhZHNz6n106IdWX2FFJJs513Oaod9\n",
       "WszriGKyr2ZCZ6Qc5/+hIJJ2+LeBgwZHyw5u8EVh8pAw5jgfEAiSU21xhqypLcWpOZbPGnJFFR0o\n",
       "wUKrUmw6PS1GJFxE1YK1971LVzRXkDNKKKhSuBKY+33uAGzF9hjj/xlyuGg7hFaUvq6ox9Xk6sN5\n",
       "4OwjT+q5MWSRtikBq8V/vcdVuvotld+kZM+IGV/7JyG/t7O46nhXTsn7ZI5GwPg5z2Q1ggDklKII\n",
       "G0aUcFs82UI8yfgXMV5w+ZpsHP0EkzsUhQecJCrJSu8vN82oCzK1Abff4Y6sEPFCqEy6FnvrPPcy\n",
       "1Gtb+XfI8pT7M9YcNiBdmN1jIWqc8undCCQLRRZzlPDM9In6BPvFf97ViDaKzWLdPDG9EELd7rUu\n",
       "WS8YQHrJShfwMdez0MhnepKqlapbSUGWThmcHUj9tn9tI5jZhfvjGag84ai6Lh6HA0uBy8bM3IAv\n",
       "+Nph8HZkvb72DYofXhbx7EP0nuDZJ+HkMI/Zyj9vv8cAQDMBpHwlkRKli9fpVhtEuUDGcc6b/6qh\n",
       "ZtR/g5FrWxbDEL915SRRlJI9KnYU4iwUuT72mXYomLVr0MxEWdu99/ZY/yPHEUACpAAtImL7gq/7\n",
       "SkrO7YBslWdzLS1Y0DuRkMqXL18tUQxRNi54cyNIHSCv1aR2EOghxUedk+iC0IzktiFNZftUXNac\n",
       "wtns/6fF+x6ZRfBVh4J+lIvGhpbp0EZCdDBouJPAwinSQQ9FHqpvO98pwztbbJEf946pf1pvRb/J\n",
       "QlzUzE13zz3S0j/Thwl4Lq+J9OsuvK5H+muBnm0GOqBP6yTyBxfGZU5r7/FBcrZh+GkWiLOyJIo2\n",
       "IIExek+tEBJY5+/EgrduH2zUvWoH/QwUOZHWYnyin674TylFi/fFfXLhV7uVjVyVn8TDWF7ApDr/\n",
       "9jq2du+nh6Qn8FKq/YcOM8E9YQbdV/uKjTwU/48gG/BwyhvwPJWyg/yJd4Q4DfMxH2gehaRMeoDI\n",
       "P3hGIHzpmGu5MeLv04l9r4gTU2VJkAbpK5qCCt5tk97hGXc3y831u4QEQ+vJDvutAgzgsn/mE2xR\n",
       "IL9K/64FVFD2rvzRjaJY8Er7T6+dqmzRWcd6kWUqfJ8CYFWUjlUnqka2XqdoyCNJBraCDN7g9Xbs\n",
       "/hHW7FBdymmwz8Bt+uE6p085OvUqDiOhaI8Ml6R3MkXAqVVLbuPOptJ/N+DyTcjek/8PJd8RV3W5\n",
       "6nvRv8e/jQzzPoroI0RJjOcSd8VbYfr7Ug838rMWj8Qwxm2jjHLNZjLR0NLmUomSJSVY8HynGR67\n",
       "WIzHK8kbrj7vIuG/DF+31F15tvTuWpmIedb8HyisRDf+Ly2gGRxWEuF9a2gHjJdY1eHUy6yAb9rP\n",
       "VFKiAAF4YVm37S3JJ3lOmz/kVtbCjrEm+aDXNnl5s50s0ybfZeMG6UECeePrskH/JN/O8zkFBrBQ\n",
       "n9YEgI/n/0dZ/VYatHGtR0JmuRIXNx+jpnLpYQo9mub8f16wdtjwIEZk+0mzCJkqmvXq9PAfDwiP\n",
       "frJT2jq4QFcrbiUaYOTp5oCw71IZTwdOpmSKjnwyaXlPsD7zauDxChIU03BQnw+yY0x4BvcabtTO\n",
       "4Xyn7B+x2LZN7kF4j4trZm1CG4TNl+GXjWazDxuxApDD86AD2d0GSUVb/itxANbsRrBvXvNlfmKt\n",
       "/Eb9FmMDnHf9dxqMZGwoUxX38aEWrxqBLEpYFHcJAshutHlmwqJsS3Ycvqz7hYOa5jpsCdGhAa9g\n",
       "4qsrcSff06VOlta2fpvsK3zsCcpU7f9UKq1TuI6uXVNlH3fOZUHgYU4aHeWql0GdBRp8pca+/xyc\n",
       "vy+wZodmZQ+wW1OG9yJciUbH4813ud1YsqY/XN/jn469ndUQl+bo0gsgxWg1Z892TmzKSRp6p9Ii\n",
       "QZkcW6UD9lc5PsaGKHARj1XEU0kJM/sG9NIy/tKTjvz//V82cSNsFAD/mH5RtACmWaKn7ZBVs/YK\n",
       "L/zGvmIfChC/XqOMUGqn095/M88zae4/lAa+wkSyfDqkWSAXEIP/he0IWGu8lMm6CSp/QBzpopTe\n",
       "ERSSJyd6laUVrS/ZdLPsSTyGEVW+56ew0ISaOxP4ZRKwTmCI/0klQ38YgI8pWgwmAwmt6ZvrEzAd\n",
       "NvrhIY2lG7rs/Wep7Q0OmKruKgN/DKkRiCGHX3XMwfbweoYk3WIjjYvxW1yTb6avt/JXmzgGviR9\n",
       "HJTk6VEC9/mxEAU7b8+mHcW2wkMIzvpedzKov9Ggr2D57s3I4CWY6hS99vXKSONvJYnIIVwCBZxC\n",
       "Pi/GHAx/iGmBlOUsqeGDZYI6v9uBC+9Oov3gPW2yCSFuAVEn6b9kHOZfA8ifx0HqmHB5TJ/vLRjT\n",
       "Z8FBn8uR06hBh3N2TapIxZhbaa96bc3T7bNYo7OZ0Z2xrYlRRzNUqJjm+mBmyR4xZy/cIapmY1af\n",
       "hLIDjDkE3KFOpcxYxYs/YaEQacxCs9deZYCcgpt/do1eeH8ZobMoTW6uWwIp/e/a6eJiJQlvhZ+S\n",
       "mNTtDdtAD4+mW5U3bSgg9ujmGpPMsD992owNkN0rAGXvFx3e6yY3/JAftp4ueWFaanVmr4S6laOV\n",
       "k3+/tr1X8uTK0uMla8t23J1R/9UlKdRYi3Crn36fgNLjIpAnW3cN2K07vNIKt+kgCEG9jmgy/nzG\n",
       "FGjUazKD3aSC9W9k6ztgkZtAIrBz0uMv7fBqU5XM+xV3cLL6go+Z67m9teOLwTNtPeBQdEEqiojf\n",
       "//o9n1WB/NrFdcW2rmCqSzFI57rBhTZPmCsmFlkki/pu/h39A0jirHyouXuXBCu+4jRalGdnIx5m\n",
       "+WgyIHA3xT3mjq/idRO4vTExEOTFMGdPBaskCBqv16RI6V9kpSIDDrh5Z/O662gcqpRTPpeC0Rua\n",
       "mF18FATKHLv3RkHbX2Gm5ZyIxVXH0vx7as+J0ZExF6L6nljf599/9xF+KyCB1xYlAq9bpe98dCJv\n",
       "ahu/xc4Q5GKGicCSzqxwcnncaqfm9+C9opkIfwn6Ah3cxjAAqlUj5Gb8ZKuyczvR03y5FBa/BmV5\n",
       "zEA+quWohRWT6FWMGqhFe2GW4nfw2cclWN5KFOuBUQAbiOn5VTXVMNt8JKbSK0/raigxYYDKfOZk\n",
       "dlXTUJkpXKYRNjy1IytTxlucFoquSKbRAzGtbZpvfZsn8sK8Wp67q88sT+/S0JKZoTkwyPHvvOxM\n",
       "X08PAi9DSm7ZqPzca2wHmnNj3rHR1yN8zvRk2hUxsVGqG25h6rnLxVo8SVCMqAV6m+YAZ79D7vNR\n",
       "MVY2X3wdk3ksmhoBVO++UZ9aYxDJWoQiaY3WyRur44o7IujJmdph1MoPtN9rEdSKj379rtWsInIS\n",
       "UJTcguO+skgyDbQACeofAAABRkGaJGxBT/7WjLADZbvpFAH3tw1Sp5+qulxq6axCAZ4mNwUEnMf3\n",
       "j96etzuHFwMFd+aFJfFZTn6gPIvhV/nyreCT1rPWfD1ljZOepzlwuuB0zqbbor+pP8qFkiS//niO\n",
       "4Hq7OJ3R5M6978uI8kQBHtR0SUY1IDFrI90lIS2Zs5fMw5BZ2kddTpgisrg/7H1h9hNHC4nUt3Rg\n",
       "PUHawynwc6tAApAHazxmJaxjNqfAy+Yx+urNxjPjvkovBEvlu/Wf4GJpKIj4Utaljiv5Dvw5Cc0J\n",
       "EHpWXXFI0NZx4BafTQD7Q8m4Dk2bt5xuKCKgyXPlSDXcYPo1Nn1haDuzVYP0u47WI2A8jNmNq6KV\n",
       "q/L+LvtFPtRvA5gaiWDf/FZJvk+Yq8xDf4cNdeCp4Uy5pya2tdjpxwrAXJXRhVvH2wPZlES81SBM\n",
       "m7xsAAAAKUGeQniCHwAQVD2ijkwVy8FjveOrcSMVJ0db8XcW2/3KnE54snrbr6GBAAAAIQGeYXRD\n",
       "/wAkq5UJCUIHXV0KOYMzfYf0SH01/9UJnvQB4QAAABcBnmNqQ/8AAAMCGwa3PNqMvMAOBzLzzwAA\n",
       "AClBmmhJqEFomUwIKf/+1oywAAAylmcGHLfK8Vs5nrqQATIEFKYeX1INgQAAABlBnoZFESwQ/wAA\n",
       "AwDyz3Cj82libC4fg+/tAAAAFwGepXRD/wAAAwIauSZJp+03UDfczLiZAAAADgGep2pD/wAAAwDn\n",
       "9kGRAAAAFEGarEmoQWyZTAgp//7WjLAAAAfcAAAAEUGeykUVLBD/AAADAGl1TUPRAAAADgGe6XRD\n",
       "/wAAAwDn18n9AAAADgGe62pD/wAAAwDn9kGRAAAAFEGa8EmoQWyZTAgp//7WjLAAAAfdAAAAEUGf\n",
       "DkUVLBD/AAADAGl1TUPRAAAADgGfLXRD/wAAAwDn18n9AAAADgGfL2pD/wAAAwDn9kGRAAAAFEGb\n",
       "NEmoQWyZTAgp//7WjLAAAAfcAAAAEUGfUkUVLBD/AAADAGl1TUPRAAAADgGfcXRD/wAAAwDn18n9\n",
       "AAAADgGfc2pD/wAAAwDn9kGRAAAAFEGbeEmoQWyZTAgp//7WjLAAAAfdAAAAEUGflkUVLBD/AAAD\n",
       "AGl1TUPQAAAADgGftXRD/wAAAwDn18n9AAAADgGft2pD/wAAAwDn9kGRAAAAFEGbvEmoQWyZTAgp\n",
       "//7WjLAAAAfcAAAAEUGf2kUVLBD/AAADAGl1TUPRAAAADgGf+XRD/wAAAwDn18n9AAAADgGf+2pD\n",
       "/wAAAwDn9kGRAAAAFEGb4EmoQWyZTAgp//7WjLAAAAfdAAAAEUGeHkUVLBD/AAADAGl1TUPQAAAA\n",
       "DgGePXRD/wAAAwDn18n9AAAADgGeP2pD/wAAAwDn9kGRAAAAFEGaJEmoQWyZTAgp//7WjLAAAAfc\n",
       "AAAAEUGeQkUVLBD/AAADAGl1TUPRAAAADgGeYXRD/wAAAwDn18n9AAAADgGeY2pD/wAAAwDn9kGR\n",
       "AAAAFEGaaEmoQWyZTAgp//7WjLAAAAfdAAAAEUGehkUVLBD/AAADAGl1TUPRAAAADgGepXRD/wAA\n",
       "AwDn18n9AAAADgGep2pD/wAAAwDn9kGRAAAAFEGarEmoQWyZTAgp//7WjLAAAAfcAAAAEUGeykUV\n",
       "LBD/AAADAGl1TUPRAAAADgGe6XRD/wAAAwDn18n9AAAADgGe62pD/wAAAwDn9kGRAAAAFEGa8Emo\n",
       "QWyZTAgp//7WjLAAAAfdAAAAEUGfDkUVLBD/AAADAGl1TUPRAAAADgGfLXRD/wAAAwDn18n9AAAA\n",
       "DgGfL2pD/wAAAwDn9kGRAAAAFEGbNEmoQWyZTAgp//7WjLAAAAfcAAAAEUGfUkUVLBD/AAADAGl1\n",
       "TUPRAAAADgGfcXRD/wAAAwDn18n9AAAADgGfc2pD/wAAAwDn9kGRAAAAFEGbeEmoQWyZTAgp//7W\n",
       "jLAAAAfdAAAAEUGflkUVLBD/AAADAGl1TUPQAAAADgGftXRD/wAAAwDn18n9AAAADgGft2pD/wAA\n",
       "AwDn9kGRAAAAFEGbvEmoQWyZTAgp//7WjLAAAAfcAAAAEUGf2kUVLBD/AAADAGl1TUPRAAAADgGf\n",
       "+XRD/wAAAwDn18n9AAAADgGf+2pD/wAAAwDn9kGRAAAAFEGb4EmoQWyZTAgp//7WjLAAAAfdAAAA\n",
       "EUGeHkUVLBD/AAADAGl1TUPQAAAADgGePXRD/wAAAwDn18n9AAAADgGeP2pD/wAAAwDn9kGRAAAA\n",
       "FEGaJEmoQWyZTAgp//7WjLAAAAfcAAAAEUGeQkUVLBD/AAADAGl1TUPRAAAADgGeYXRD/wAAAwDn\n",
       "18n9AAAADgGeY2pD/wAAAwDn9kGRAAAAFEGaaEmoQWyZTAgp//7WjLAAAAfdAAAAEUGehkUVLBD/\n",
       "AAADAGl1TUPRAAAADgGepXRD/wAAAwDn18n9AAAADgGep2pD/wAAAwDn9kGRAAAAFEGarEmoQWyZ\n",
       "TAgp//7WjLAAAAfcAAAAEUGeykUVLBD/AAADAGl1TUPRAAAADgGe6XRD/wAAAwDn18n9AAAADgGe\n",
       "62pD/wAAAwDn9kGRAAAAFEGa8EmoQWyZTAgn//61KoAAAB6xAAAAEUGfDkUVLBD/AAADAGl1TUPR\n",
       "AAAADgGfLXRD/wAAAwDn18n9AAAADgGfL2pD/wAAAwDn9kGRAAAAFEGbNEmoQWyZTAgn//61KoAA\n",
       "AB6wAAAAEUGfUkUVLBD/AAADAGl1TUPRAAAADgGfcXRD/wAAAwDn18n9AAAADgGfc2pD/wAAAwDn\n",
       "9kGRAAAAFEGbeEmoQWyZTAgn//61KoAAAB6xAAAAEUGflkUVLBD/AAADAGl1TUPQAAAADgGftXRD\n",
       "/wAAAwDn18n9AAAADgGft2pD/wAAAwDn9kGRAAAAFEGbvEmoQWyZTAgn//61KoAAAB6wAAAAEUGf\n",
       "2kUVLBD/AAADAGl1TUPRAAAADgGf+XRD/wAAAwDn18n9AAAADgGf+2pD/wAAAwDn9kGRAAAAFEGb\n",
       "4EmoQWyZTAgj//61KoAAAB6xAAAAEUGeHkUVLBD/AAADAGl1TUPQAAAADgGePXRD/wAAAwDn18n9\n",
       "AAAADgGeP2pD/wAAAwDn9kGRAAAAFkGaIkmoQWyZTBRMP//+qZYAAAMA8IAAAAAPAZ5BakP/AAAD\n",
       "AOgF+IlBAAAH0m1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAE1YAAEAAAEAAAAAAAAAAAAA\n",
       "AAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAIAAAb8dHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAE1YAAAAAAAAAAAA\n",
       "AAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAGwAAABIAAAAAAAJGVk\n",
       "dHMAAAAcZWxzdAAAAAAAAAABAABNWAAAEAAAAQAAAAAGdG1kaWEAAAAgbWRoZAAAAAAAAAAAAAAA\n",
       "AAAAKAAAAxgAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVy\n",
       "AAAABh9taW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAM\n",
       "dXJsIAAAAAEAAAXfc3RibAAAALNzdHNkAAAAAAAAAAEAAACjYXZjMQAAAAAAAAABAAAAAAAAAAAA\n",
       "AAAAAAAAAAGwASAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "ABj//wAAADFhdmNDAWQAFf/hABhnZAAVrNlBsJaEAAADAAQAAAMAKDxYtlgBAAZo6+PLIsAAAAAc\n",
       "dXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAAAGMAAAgAAAAAFHN0c3MA\n",
       "AAAAAAAAAQAAAAEAAAMoY3R0cwAAAAAAAABjAAAAAQAAEAAAAAABAAAoAAAAAAEAABAAAAAAAQAA\n",
       "AAAAAAABAAAIAAAAAAEAACgAAAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAQAAKAAAAAABAAAQ\n",
       "AAAAAAEAAAAAAAAAAQAACAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEAACgA\n",
       "AAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAA\n",
       "AAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEAACgAAAAAAQAAEAAAAAABAAAAAAAA\n",
       "AAEAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAoAAAAAAEAABAAAAAA\n",
       "AQAAAAAAAAABAAAIAAAAAAEAACgAAAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAQAAKAAAAAAB\n",
       "AAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEA\n",
       "ACgAAAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAA\n",
       "CAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEAACgAAAAAAQAAEAAAAAABAAAA\n",
       "AAAAAAEAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAoAAAAAAEAABAA\n",
       "AAAAAQAAAAAAAAABAAAIAAAAAAEAACgAAAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAQAAKAAA\n",
       "AAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAA\n",
       "AAEAACgAAAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAA\n",
       "AQAACAAAAAABAAAYAAAAAAEAAAgAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAABjAAAAAQAAAaBzdHN6\n",
       "AAAAAAAAAAAAAABjAAAXfQAAAUoAAAAtAAAAJQAAABsAAAAtAAAAHQAAABsAAAASAAAAGAAAABUA\n",
       "AAASAAAAEgAAABgAAAAVAAAAEgAAABIAAAAYAAAAFQAAABIAAAASAAAAGAAAABUAAAASAAAAEgAA\n",
       "ABgAAAAVAAAAEgAAABIAAAAYAAAAFQAAABIAAAASAAAAGAAAABUAAAASAAAAEgAAABgAAAAVAAAA\n",
       "EgAAABIAAAAYAAAAFQAAABIAAAASAAAAGAAAABUAAAASAAAAEgAAABgAAAAVAAAAEgAAABIAAAAY\n",
       "AAAAFQAAABIAAAASAAAAGAAAABUAAAASAAAAEgAAABgAAAAVAAAAEgAAABIAAAAYAAAAFQAAABIA\n",
       "AAASAAAAGAAAABUAAAASAAAAEgAAABgAAAAVAAAAEgAAABIAAAAYAAAAFQAAABIAAAASAAAAGAAA\n",
       "ABUAAAASAAAAEgAAABgAAAAVAAAAEgAAABIAAAAYAAAAFQAAABIAAAASAAAAGAAAABUAAAASAAAA\n",
       "EgAAABoAAAATAAAAFHN0Y28AAAAAAAAAAQAAACwAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxy\n",
       "AAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAA\n",
       "TGF2ZjU4LjIwLjEwMA==\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the policy\n",
    "thetaVals = np.zeros((100,1))\n",
    "for i in range(100):\n",
    "    \n",
    "    st = policy[i]\n",
    "    thetaVals[i],_ = get_values(st)\n",
    "    \n",
    "    \n",
    "plt.plot(range(100), thetaVals)\n",
    "draw_pendulum(thetaVals)\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"theta$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def freependulum(state):\n",
    "    '''\n",
    "    To check dynamics of pendulum without control. \n",
    "    This function takes a state value from 0 to 2499 and displays SHM of pendulum with 0 force.  \n",
    "    '''\n",
    "    freeswing = np.zeros([100,1])\n",
    "    freeswingtheta = np.zeros([100,1])\n",
    "    for i in range(50):\n",
    "        freeswing[i] = next_states[state,2]\n",
    "        sat = int(freeswing[i])\n",
    "        freeswingtheta[i],_ = get_values(state)\n",
    "\n",
    "\n",
    "    plt.plot(range(100), freeswingtheta)\n",
    "    draw_pendulum(freeswingtheta)\n",
    "    plt.xlabel(\"time (ms)\")\n",
    "    plt.ylabel(\"theta\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freependulum(1035)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
